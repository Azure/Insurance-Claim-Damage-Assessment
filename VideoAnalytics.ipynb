{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89139243",
   "metadata": {},
   "source": [
    "Ref: https://github.com/openai/openai-cookbook/blob/main/examples/gpt4o/introduction_to_gpt4o.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ec2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "import os\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import time\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "import time\n",
    "import base64\n",
    "import gradio as gr\n",
    "import base64\n",
    "import os\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import  requests\n",
    "import requests\n",
    "import json\n",
    "import urllib.request\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422603ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./processed_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bffb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7705141",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "endpoint = os.getenv(\"OPEN_AI_ENDPOINT\")\n",
    "api_key = os.getenv(\"OPEN_AI_KEY\")\n",
    "model_ep = os.getenv(\"MODEL_EP\")\n",
    "model_key = os.getenv(\"MODEL_KEY\")\n",
    "\n",
    "deployment_azure = os.getenv(\"OPEN_AI_DEPLOYMENT\")\n",
    "      \n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "      \n",
    "client_azure = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-02-01\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2324ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ffmpeg -i data/FY25Strategy_compressed.mp4 -vcodec libx264 -preset ultrafast -crf 28 -acodec aac -b:a 128k FY25Strategy_compressed1.mp4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd32d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(data, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def get_pickle_path(video_name, start, end):\n",
    "    \"\"\"Generates a file path for the pickle file based on the frame range.\"\"\"\n",
    "    return os.path.join(output_dir, f\"{video_name}_summary_{start}_{end}.pkl\")\n",
    "\n",
    "def get_final_summary_path(video_name):\n",
    "    \"\"\"Generates a file path for the pickle file based on the frame range.\"\"\"\n",
    "    return os.path.join(output_dir, f\"{video_name}_final_summary.pkl\")\n",
    "\n",
    "def get_phi3_final_summary_path(video_name):\n",
    "    \"\"\"Generates a file path for the pickle file based on the frame range.\"\"\"\n",
    "    return os.path.join(output_dir, f\"{video_name}_phi3_final_summary.pkl\")\n",
    "\n",
    "def get_phi3_pickle_path(video_name, start, end):\n",
    "    \"\"\"Generates a file path for the pickle file based on the frame range.\"\"\"\n",
    "    return os.path.join(output_dir, f\"{video_name}_phi3_summary_{start}_{end}.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94f74609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_response(input_data, ep=model_ep, key=model_key):\n",
    "    #print(input_data)\n",
    "    body = str.encode(json.dumps(input_data))\n",
    "    if not model_key:\n",
    "        raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "    headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ key)}\n",
    "    req = urllib.request.Request(ep, body, headers)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "        result = response.read()\n",
    "        return json.loads(result.decode(\"utf8\", 'ignore'))\n",
    "    except urllib.error.HTTPError as error:\n",
    "        print(\"The request failed with status code: \" + str(error.code))\n",
    "        print(error.info())\n",
    "        print(error.read().decode(\"utf8\", 'ignore'))\n",
    "        \n",
    "def get_frameset_summary_phi3(pickle_file_path, base64Frames, start, end, regen=False, in_prompt=\"\"):\n",
    "    print(pickle_file_path)\n",
    "    if regen==False and os.path.exists(pickle_file_path):\n",
    "        content = load_pickle(pickle_file_path)\n",
    "        print(f\"Loaded existing summary for frames {start} to {end}.\")\n",
    "    else:\n",
    "        if in_prompt == \"\":\n",
    "            in_prompt = \"\"\"Extract following details about the car in the image:\n",
    "1. Whether the car is facing sideways, from or back. \n",
    "2. Dents /Scrtches visible in the car detailing where thet are visible.\n",
    "3. Shattered windows of the car, including details of which windows of the car.\n",
    "4. Damages to front/back bumber of the car.\n",
    "5. Do not make up any info, stay grounded to the provided image.\n",
    "6. Number plate of the car.\n",
    "7. Any other info that would be of interest to insurance company.\n",
    "6. Stay truthful.\"\"\"\n",
    "        user_content=[\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": in_prompt\n",
    "            },\n",
    "            *map(lambda x: {\"type\": \"image_url\", \n",
    "                            \"image_url\": {\"url\": f'data:image/jpg;base64,{x}'}}, base64Frames[start:end])\n",
    "        ]\n",
    "       \n",
    "        \n",
    "        input_data = {\n",
    "            \"input_data\": {\n",
    "            \"input_string\": [\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_content\n",
    "              }\n",
    "            ],\n",
    "            \"parameters\": { \"temperature\": 0.7, \"max_new_tokens\": 2048 }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        \n",
    "        results = get_response(input_data)\n",
    "        print(results)\n",
    "        \n",
    "        content = results[\"output\"]\n",
    "        save_pickle(content, pickle_file_path) \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae3949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f09cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    base64Frames = []\n",
    "    pickle_file_path = \"test.pkl\"\n",
    "    file_path = \"processed_files/car_frame_75.jpg\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        buffer = file.read()\n",
    "        base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "    in_prompt = \"\"\"Extract following details about the car in the image:\n",
    "    1. Whether the car is facing sideways, from or back. \n",
    "    2. Dents /Scrtches visible in the car detailing where thet are visible.\n",
    "    3. Shattered windows of the car, including details of which windows of the car.\n",
    "    4. Damages to front/back bumber of the car.\n",
    "    5. Do not make up any info, stay grounded to the provided image.\n",
    "    6. Number plate of the car.\n",
    "    7. Any other info that would be of interest to insurance company.\n",
    "    6. Stay truthful.\"\"\"\n",
    "    get_frameset_summary_phi3(pickle_file_path, base64Frames, 0, 1, True, in_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0589f475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\urllib\\request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\http\\client.py\", line 1303, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\http\\client.py\", line 1349, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\http\\client.py\", line 1298, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\http\\client.py\", line 1058, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\http\\client.py\", line 996, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\http\\client.py\", line 1468, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\http\\client.py\", line 962, in connect\n",
      "    self.sock = self._create_connection(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\socket.py\", line 827, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\socket.py\", line 962, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\site-packages\\gradio\\route_utils.py\", line 321, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\site-packages\\gradio\\blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\site-packages\\gradio\\blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\site-packages\\gradio\\utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\AppData\\Local\\Temp\\ipykernel_8384\\3054743911.py\", line 113, in summarize\n",
      "    phi3_content = get_frameset_summary_phi3(phi3_pickle_file_path, base64Frames, start, end)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\AppData\\Local\\Temp\\ipykernel_8384\\1745557628.py\", line 57, in get_frameset_summary_phi3\n",
      "    results = get_response(input_data)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\AppData\\Local\\Temp\\ipykernel_8384\\1745557628.py\", line 10, in get_response\n",
      "    response = urllib.request.urlopen(req)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\urllib\\request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\urllib\\request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\urllib\\request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\urllib\\request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\urllib\\request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shagrawal\\Miniconda3\\envs\\va\\Lib\\urllib\\request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ensure the short path for saving processed files\n",
    "\n",
    "\n",
    "all_responses= []\n",
    "all_phi3_responses= []\n",
    "def get_frameset_summary(pickle_file_path, base64Frames, start, end):\n",
    "    print(pickle_file_path)\n",
    "    if os.path.exists(pickle_file_path):\n",
    "        content = load_pickle(pickle_file_path)\n",
    "        #response = eval(response)\n",
    "        print(f\"Loaded existing summary for frames {start} to {end}.\")\n",
    "    else:\n",
    "        try:\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You generate detailed note for inspection of a car for insurance company. \n",
    "    You keep the note grounded on info provided to you as Inspection details. \n",
    "    You respond in Markdown/bulleted list of points so as to make the inpformation easy to understand.\n",
    "    \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\n",
    "                      \"type\": \"text\",\n",
    "                      \"text\": \"These are the frames from the video.\"\n",
    "                    },\n",
    "                    *map(lambda x: {\"type\": \"image_url\", \n",
    "                                    \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"high\"}}, base64Frames[start:end])\n",
    "                    ],\n",
    "                }\n",
    "                ]\n",
    "\n",
    "            response = client_azure.chat.completions.create(\n",
    "                model=deployment_azure,\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "            )\n",
    "            #print(response.choices[0].message.content)\n",
    "            save_pickle(response.choices[0].message.content, pickle_file_path) \n",
    "            content = response.choices[0].message.content\n",
    "        except:\n",
    "            content=\"\"\n",
    "    return content\n",
    "\n",
    "def get_final_summary(base_video_path, in_responses, pickle_file_path):\n",
    "    \n",
    "    if os.path.exists(pickle_file_path):\n",
    "        content = load_pickle(pickle_file_path)\n",
    "        return content\n",
    "    all_notes = \"\\nNotes:\\n\".join(in_responses)\n",
    "    \n",
    "    try:\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"\n",
    "You generate detailed note for inspection of a car for insurance company. \n",
    "You keep the note grounded on info provided to you as Inspection details. \n",
    "You create a consolidated summary based on notes created by inspecting car from different angles.\n",
    "All notes are for same car.\n",
    "You respond in html tabluar format so as to make the information easy to understand.\n",
    "\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                  \"type\": \"text\",\n",
    "                  \"text\": f\"Inspection details: {all_notes}\"\n",
    "                },\n",
    "                ],\n",
    "            }\n",
    "            ]\n",
    "\n",
    "        response = client_azure.chat.completions.create(\n",
    "            model=deployment_azure,\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "        )\n",
    "        #print(response.choices[0].message.content)\n",
    "        content = response.choices[0].message.content\n",
    "        save_pickle(content, pickle_file_path) \n",
    "    except:\n",
    "        content=\"\"\n",
    "    return content\n",
    "        \n",
    "        \n",
    "def summarize(in_gallery):\n",
    "    base64Frames = []\n",
    "    #print(in_gallery)\n",
    "    base_video_path = \"\"\n",
    "    # Convert file paths to base64-encoded frames\n",
    "    for file_path in in_gallery:\n",
    "        print(file_path)\n",
    "        # If item is a tuple, unpack it\n",
    "        #if isinstance(file_path, dict) and 'name' in file_path:\n",
    "        #    file_path = file_path['name']\n",
    "        #    print(\"dict\")\n",
    "        #elif isinstance(file_path, tuple):\n",
    "        file_path = file_path[0]\n",
    "            \n",
    "        if base_video_path == \"\":\n",
    "            #print(file_path)\n",
    "            base_video_path = file_path.split(\".\")[0].split(\"\\\\\")[-1]\n",
    "            #print(f\"Base File Path: {base_video_path}\")\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            buffer = file.read()\n",
    "            base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "            \n",
    "    \n",
    "    start = 0\n",
    "    batch_size = 2\n",
    "    end = start + batch_size\n",
    "    print(f\"No. of frames:{len(base64Frames)}\")\n",
    "    while end<= len(base64Frames):\n",
    "        \n",
    "        pickle_file_path = get_pickle_path(base_video_path, start, end)\n",
    "        content = get_frameset_summary(pickle_file_path, base64Frames, start, end)\n",
    "        \n",
    "        phi3_pickle_file_path = get_phi3_pickle_path(base_video_path, start, end)\n",
    "        phi3_content = get_frameset_summary_phi3(phi3_pickle_file_path, base64Frames, start, end)\n",
    "        \n",
    "        \n",
    "        all_responses.append(content)\n",
    "        all_phi3_responses.append(phi3_content)\n",
    "        if end == len(base64Frames):\n",
    "            break;\n",
    "        end += batch_size\n",
    "        if end > len(base64Frames):\n",
    "            end = len(base64Frames)\n",
    "        start += batch_size\n",
    "        \n",
    "    pickle_file_path = get_final_summary_path(base_video_path)\n",
    "    phi3_pickle_file_path = get_phi3_final_summary_path(base_video_path)\n",
    "    print(all_phi3_responses)\n",
    "    final_summary = get_final_summary(base_video_path, all_responses, pickle_file_path)\n",
    "    final_summary_phi3 = get_final_summary(base_video_path, all_phi3_responses, phi3_pickle_file_path)\n",
    "    return \"Final Summary:\" + final_summary, \"Final Summary:\" + final_summary_phi3\n",
    "\n",
    "\n",
    "\n",
    "def process_video(video_path, seconds_per_frame=2):\n",
    "    frame_paths = []\n",
    "    video_name = os.path.basename(video_path)\n",
    "    base_video_path = os.path.join(output_dir, os.path.splitext(video_name)[0])\n",
    "\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frames_to_skip = int(fps * seconds_per_frame)\n",
    "    curr_frame = 0\n",
    "\n",
    "    # Loop through the video and extract frames at specified sampling rate\n",
    "    while curr_frame < total_frames - 1:\n",
    "        frame_path = f\"{base_video_path}_frame_{curr_frame}.jpg\"\n",
    "        #print(f\"Frame  {frame_path}.\")\n",
    "        if os.path.exists(frame_path):\n",
    "            print(print(f\"Frame  {frame_path} already exists.\"))\n",
    "        else:\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
    "            success, frame = video.read()\n",
    "            if not success:\n",
    "                break\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "        frame_paths.append(frame_path)\n",
    "        curr_frame += frames_to_skip\n",
    "    video.release()\n",
    "\n",
    "    # Extract audio from video\n",
    "    audio_path = f\"{base_video_path}.mp3\"\n",
    "    if os.path.exists(audio_path):\n",
    "        print(f\"Audio file {audio_path} already exists.\")\n",
    "    else:\n",
    "        clip = VideoFileClip(video_path)\n",
    "        clip.audio.write_audiofile(audio_path, bitrate=\"32k\")\n",
    "        clip.audio.close()\n",
    "        clip.close()\n",
    "\n",
    "    print(f\"Extracted {len(frame_paths)} frames\")\n",
    "    print(f\"Extracted audio to {audio_path}\")\n",
    "    return frame_paths, audio_path\n",
    "\n",
    "def handle_video_upload(video_file_path):\n",
    "    frame_paths, audio_path = process_video(video_file_path, seconds_per_frame=0.5)\n",
    "    return frame_paths, audio_path\n",
    "\n",
    "\n",
    "def upload_video(video):\n",
    "    print(video)\n",
    "    final_video = video\n",
    "    if video:\n",
    "        final_video = video.replace(\"\\\\\", \"/\")\n",
    "        print(final_video)\n",
    "    return gr.update(True),gr.update(False), final_video, video\n",
    "\n",
    "custom_css = \"\"\"\n",
    "#input-video video {\n",
    "    height: 400px;  /* Set your desired max height here */\n",
    "}\n",
    "#output-video video {\n",
    "    height: 400px;  /* Set your desired max height here */\n",
    "}\n",
    "\"\"\"\n",
    "# Create the Gradio Blocks interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Unleash Innovation with Azure Open AI\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            video_input = gr.Video()\n",
    "            #video_output = gr.Video()\n",
    "    \n",
    "    \n",
    "    process_button = gr.Button(\"Process\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            output_gallery = gr.Gallery(label=\"Extracted Frames\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            txt_summary = gr.HTML(label=\"Video Summary\")\n",
    "        with gr.Column():\n",
    "            txt_summary_phi3 = gr.HTML(label=\"Video Summary - Phi3\")\n",
    "    with gr.Row():\n",
    "        output_audio = gr.Audio(label=\"Extracted Audio\")\n",
    "    with gr.Row():\n",
    "        summarize_button = gr.Button(\"Summarize\")\n",
    "\n",
    "    #video_input.change(fn=upload_video, inputs=video_input, outputs=[video_input,video_output,video_input, video_output])\n",
    "    #video_input.change(fn=upload_video, inputs=video_input, outputs=[video_input,video_input,video_input, video_input])\n",
    "    process_button.click(fn=handle_video_upload, inputs=video_input, outputs=[output_gallery, output_audio])\n",
    "    summarize_button.click(fn=summarize, inputs=output_gallery, outputs=[txt_summary,txt_summary_phi3])\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c217d",
   "metadata": {},
   "source": [
    "# Whats New \n",
    "https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/announcing-multimodal-innovations-in-generative-ai-with-azure/ba-p/4146804\n",
    "1. GPT4o will have global deployments - Public Preview \n",
    "2. Customers will be able to purchase today - 21 May 24\n",
    "3. Multi Modality \n",
    "4. Option to turn it off to be available in few weeks\n",
    "5. Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b39aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
